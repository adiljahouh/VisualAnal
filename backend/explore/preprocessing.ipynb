{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import csv\n",
    "import glob\n",
    "import codecs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [],
   "source": [
    "def pre_process_txt_file(file_path):\n",
    "    # Read in the file as UTF-8\n",
    "    with codecs.open(file_path, 'r', encoding='utf-8', errors='ignore') as f:\n",
    "        text = f.read()\n",
    "    \n",
    "    # Remove double quotes and empty lines\n",
    "    text = text.replace('\"', '').strip()\n",
    "    text = text.replace(',', '').strip()\n",
    "    text = '\\n'.join([line for line in text.split('\\n') if line.strip() != ''])\n",
    "    \n",
    "    # Split into journal, title, date, and content\n",
    "    lines = text.split('\\n')\n",
    "    if len(lines) < 3:\n",
    "        return None\n",
    "    journal = lines[0]\n",
    "    title = lines[1]\n",
    "    date = lines[2]\n",
    "    content = ''.join(lines[3:])\n",
    "    content.replace('\\n', '')\n",
    "    \n",
    "    # Return the pre-processed data\n",
    "    return [journal, title, date, content]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_txt_files(directory, output_file):\n",
    "    # Get all .txt files in the directory\n",
    "    txt_files = glob.glob(directory + '/*.txt')\n",
    "    \n",
    "    # Open the output CSV file for writing\n",
    "    with open(output_file, 'w', newline='') as file:\n",
    "        writer = csv.writer(file)\n",
    "        \n",
    "        # Write the header row\n",
    "        writer.writerow(['journal', 'title', 'date', 'content'])\n",
    "        \n",
    "        # Loop through each .txt file and process it\n",
    "        for txt_file in txt_files:\n",
    "            # Use the pre_process_txt_file function to extract the sections from the file\n",
    "            sections = pre_process_txt_file(txt_file)\n",
    "            \n",
    "            # Write the sections as a row in the CSV file\n",
    "            writer.writerow(sections)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess_date_column(input_file, output_file):\n",
    "    # Read in the CSV file\n",
    "    df = pd.read_csv(input_file)\n",
    "    \n",
    "    # Print the number of rows before dropping\n",
    "    print(f'Number of rows before dropping: {len(df)}')\n",
    "    \n",
    "    # Convert the 'date' column to datetime\n",
    "    df['date'] = pd.to_datetime(df['date'], errors='coerce')\n",
    "    \n",
    "    # Drop rows where the 'date' column could not be converted\n",
    "    df.dropna(subset=['date'], inplace=True)\n",
    "    \n",
    "    # Print the number of rows after dropping\n",
    "    print(f'Number of rows after dropping: {len(df)}')\n",
    "    \n",
    "    # Write the results to a new CSV file\n",
    "    df.to_csv(output_file, index=False)\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [],
   "source": [
    "process_txt_files('data/articles', 'results/input.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of rows before dropping: 843\n",
      "Number of rows after dropping: 678\n"
     ]
    }
   ],
   "source": [
    "df = preprocess_date_column('results/input.csv', 'results/input_cleaned.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>journal</th>\n",
       "      <th>title</th>\n",
       "      <th>date</th>\n",
       "      <th>content</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>The Tulip</td>\n",
       "      <td>THE PLACE OF THE BEND TISKELE OF THE ROCKS GAS...</td>\n",
       "      <td>2000-08-16</td>\n",
       "      <td>ABILA Kronos - a explosion at surrounding the ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Modern Rubicon</td>\n",
       "      <td>ON SCENE BLOG</td>\n",
       "      <td>2014-01-20</td>\n",
       "      <td>MODERNIZATION 1947 - from the news conference ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>International News</td>\n",
       "      <td>Police Hold News Conference on GAStech Kidnapp...</td>\n",
       "      <td>2014-01-21</td>\n",
       "      <td>ABILA Kronos - The Abila police held a press c...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Tethys News</td>\n",
       "      <td>To break off itself: The emergency to GAStech ...</td>\n",
       "      <td>2014-01-20</td>\n",
       "      <td>Modernization 1:40 PM:  There are puttinges in...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Worldwise</td>\n",
       "      <td>Annual ends of gathering of POK in the riot still</td>\n",
       "      <td>2013-06-22</td>\n",
       "      <td>ABILA Kronos - the members of POK held their a...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "              journal                                              title  \\\n",
       "1           The Tulip  THE PLACE OF THE BEND TISKELE OF THE ROCKS GAS...   \n",
       "2      Modern Rubicon                                      ON SCENE BLOG   \n",
       "3  International News  Police Hold News Conference on GAStech Kidnapp...   \n",
       "4         Tethys News  To break off itself: The emergency to GAStech ...   \n",
       "5           Worldwise  Annual ends of gathering of POK in the riot still   \n",
       "\n",
       "        date                                            content  \n",
       "1 2000-08-16  ABILA Kronos - a explosion at surrounding the ...  \n",
       "2 2014-01-20  MODERNIZATION 1947 - from the news conference ...  \n",
       "3 2014-01-21  ABILA Kronos - The Abila police held a press c...  \n",
       "4 2014-01-20  Modernization 1:40 PM:  There are puttinges in...  \n",
       "5 2013-06-22  ABILA Kronos - the members of POK held their a...  "
      ]
     },
     "execution_count": 83,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1      1226\n",
       "2       667\n",
       "3       526\n",
       "4       266\n",
       "5      1189\n",
       "       ... \n",
       "837     294\n",
       "838     208\n",
       "839     298\n",
       "840    1092\n",
       "842     927\n",
       "Name: content, Length: 678, dtype: int64"
      ]
     },
     "execution_count": 84,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['content'].str.len()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('results/input_cleaned.csv', 'r') as f:\n",
    "    text = f.read()\n",
    "    lines = text.split('\\n')\n",
    "    for line in lines:\n",
    "        if '\\n' in line:\n",
    "            print('!')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
